---
title: Analysis at Scale
narratives:
---

**Scenario:**

I am working with a really large and complex dataset, stored across
multiple locations.  I have a workflow that I run on this dataset and
I’d like to update it as new data is added. I don’t have the memory or
compute power to do this as a robust process, and the data is too
large for me to download.

**Current approach:**

I have scraped together my own tools and some open source software to
make this happen. It is an involved process that is not automatic, and
takes quite a bit of time running sequential processes that I’d rather
spend on the interesting research. I also can’t do this at the scale
that is required because the data is inherently messy. It requires time
on a large computing hub at my institution.

**With Data Commons Phase 1:**

Standards for interoperability of tools and harmonization of data and
metadata will let me run this in th ecloud.

**With Data Commons longer vision:**

Access to large datasets through single log-in. Data Commons will
provide a collaborative environment for research and development. The
new ideas and tools from the community will be consumed in the Data
Commons and contribute to its long term value and sustainability. A
built in user community.
